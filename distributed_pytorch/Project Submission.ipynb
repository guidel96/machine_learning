{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17517393",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sources\" data-toc-modified-id=\"Sources-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sources</a></span></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Brief-Summary\" data-toc-modified-id=\"Brief-Summary-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Brief Summary</a></span></li><li><span><a href=\"#Some-notes\" data-toc-modified-id=\"Some-notes-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Some notes</a></span></li></ul></li><li><span><a href=\"#TRAINING\" data-toc-modified-id=\"TRAINING-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TRAINING</a></span><ul class=\"toc-item\"><li><span><a href=\"#MODELING\" data-toc-modified-id=\"MODELING-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>MODELING</a></span></li><li><span><a href=\"#IMPORTS\" data-toc-modified-id=\"IMPORTS-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>IMPORTS</a></span></li><li><span><a href=\"#DATA-LOADING\" data-toc-modified-id=\"DATA-LOADING-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>DATA LOADING</a></span><ul class=\"toc-item\"><li><span><a href=\"#Metadata\" data-toc-modified-id=\"Metadata-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Metadata</a></span></li></ul></li><li><span><a href=\"#TRANSFORMATIONS\" data-toc-modified-id=\"TRANSFORMATIONS-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>TRANSFORMATIONS</a></span></li><li><span><a href=\"#MODEL-PARAMETERS\" data-toc-modified-id=\"MODEL-PARAMETERS-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>MODEL PARAMETERS</a></span></li><li><span><a href=\"#TRAINING-function:-setup\" data-toc-modified-id=\"TRAINING-function:-setup-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>TRAINING function: setup</a></span></li></ul></li><li><span><a href=\"#Prediction-Pipeline\" data-toc-modified-id=\"Prediction-Pipeline-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Prediction Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#Node-0-:-collecting-metadata\" data-toc-modified-id=\"Node-0-:-collecting-metadata-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Node 0 : collecting metadata</a></span></li><li><span><a href=\"#Node-1-:-opening-+-transforming-the-images\" data-toc-modified-id=\"Node-1-:-opening-+-transforming-the-images-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Node 1 : opening + transforming the images</a></span></li><li><span><a href=\"#Nodes-2-and-3:-Predicting-the-class-of-the-image\" data-toc-modified-id=\"Nodes-2-and-3:-Predicting-the-class-of-the-image-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Nodes 2 and 3: Predicting the class of the image</a></span></li><li><span><a href=\"#Node-0:-collects-the-predicted-classes\" data-toc-modified-id=\"Node-0:-collects-the-predicted-classes-4.3.4\"><span class=\"toc-item-num\">4.3.4&nbsp;&nbsp;</span>Node 0: collects the predicted classes</a></span></li></ul></li></ul></li><li><span><a href=\"#Launching-the-.py-files\" data-toc-modified-id=\"Launching-the-.py-files-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Launching the .py files</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Training-Part\" data-toc-modified-id=\"Training-Part-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>Training Part</a></span></li><li><span><a href=\"#Predicting-part\" data-toc-modified-id=\"Predicting-part-5.0.2\"><span class=\"toc-item-num\">5.0.2&nbsp;&nbsp;</span>Predicting part</a></span></li></ul></li></ul></li><li><span><a href=\"#Improving-the-model\" data-toc-modified-id=\"Improving-the-model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Improving the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-notes\" data-toc-modified-id=\"Some-notes-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Some notes</a></span></li><li><span><a href=\"#Model-choices\" data-toc-modified-id=\"Model-choices-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Model choices</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0ed34",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "Some useful links:\n",
    "    \n",
    "- How to change the weights of a pytorch model?  \n",
    "https://discuss.pytorch.org/t/how-to-change-the-weights-of-a-pytorch-model/41279 \n",
    "    \n",
    "- Averaging weights of two models  \n",
    "https://discuss.pytorch.org/t/average-each-weight-of-two-models/77008 \n",
    "\n",
    "- Best way to compute the average of multiple models  \n",
    "https://discuss.pytorch.org/t/best-way-to-compute-the-average-of-multiple-models/120098\n",
    "\n",
    "- state_dict in Pytorch  \n",
    "https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html  \n",
    "https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_models_for_inference.html\n",
    "\n",
    "- some info about distributed computing in Pytorch  \n",
    "https://spell.ml/blog/pytorch-distributed-data-parallel-XvEaABIAAB8Ars0e\n",
    "https://www.kaggle.com/residentmario/notes-on-parallel-distributed-training-in-pytorch\n",
    "\n",
    "- Revisiting ResNets: Improved Training and Scaling Strategies  \n",
    "https://wandb.ai/wandb_fc/pytorch-image-models/reports/Revisiting-ResNets-Improved-Training-and-Scaling-Strategies--Vmlldzo2NDE3NTM\n",
    "\n",
    "- course's TPs\n",
    "\n",
    "- Very interesting starter project submitted by a Kaggle user  \n",
    "https://www.kaggle.com/ateplyuk/herb2021-pytorch-starter\n",
    "\n",
    "- training two models on two different data parts and averaging the gradients \n",
    "https://discuss.pytorch.org/t/manually-modify-gradients-of-two-models-average-them-and-put-them-back-in-both-models/80786"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699ffbe",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook I present what I have done in order to tackle the different tasks of the assignment. In order to better explain the code, I have pasted it in different cells of this notebook, that I try to complement with some explanations. The actual code that is being run by the terminal is stored in two .py files.\n",
    "\n",
    "Since the training and the prediction steps are different, I have decided to split those steps in two separate files. It must be paid attention that the transforms performed on the data are the same between both files. Further, I will provide some code that allows to save the trained model and to load it in the prediction step, if needed. \n",
    "\n",
    "I have also had some constraints during this assignment, especially regarding my laptop, and these will be explained below.\n",
    "\n",
    "Link to Kaggle dataset/competition: https://www.kaggle.com/c/herbarium-2021-fgvc8 \n",
    "\n",
    "\n",
    "## Brief Summary\n",
    "\n",
    "In this notebook I present how a ResNet 34 deep learning model was implemented in a parallel way, using PyTorch and MPI, in order to predict the classes of plant images. The training occurred in a way such that the dataset is split into smaller subdatasets and distributed on different nodes (i.e. data parallelism), and a ResNet 34 model is trained on each of these nodes. Consistency between the ResNet models is ensured by averaging the weights of the different models at each epoch.\n",
    "\n",
    "A specific pipeline is also designed to make predictions on new (unlabeled) input data.\n",
    "\n",
    "\n",
    "## Some notes\n",
    "\n",
    "I believe it is important to make some clarifications before starting:   \n",
    "\n",
    "\n",
    "- **my laptop is not optimal to do such tasks:**    \n",
    "\n",
    "\n",
    "My laptop only has only one processor with 2 cores (that are quite slow). This implies that although I can use more than two nodes in MPI, in practice it will not change much since those MPI workers will be run by the same core. Hence, I cannot observe the benefits of parallel computing as I would have done using a cluster or even a more modern laptop.\n",
    "My laptop is also limited by the memory since it has only 4GB of RAM. While data can still be stored and retrieved from disk memory, accessing disk memory is much slower than accessing RAM memory. Therefore, it needs to constantly move data from disk to RAM in blocks, which can be very slow. Hence, processing on large datasets on this laptop would take a lot of time. In practice, my laptop freezed when trying some parameters that were too high (e.g. higher image resolution). \n",
    "\n",
    "I found out that in most of the trials I have done, my laptop freezed after several epochs and rebooted automatically. I hope this will not affect the grading of the assignment too much.\n",
    "\n",
    "- **I did not manage to download more than 100 images from Kaggle:**  \n",
    "\n",
    "While downloading images from Kaggle using the API, it blocked after 300 downloads. In total, these 300 downloads correspond to folders and images. Amongst these, only 100 images were found. It also only downloaded images from the train set, and not from the test set. \n",
    "\n",
    "\n",
    "Since I am not able train the model in a fast way, and since the data that is used for training represents only at most 100 different classes (out of 64 500 possible classes), the model will never become very accurate and will only learn, at best, to predict a very limited number of classes.\n",
    "\n",
    "Splitting the limited number of images (i.e. 100) I have into a training set and a validation set would force me to use even less images for training, and this validation set should only contain classes that are also in the training set, otherwise it wouldn't make much sense (i.e. predicting classes where the data was not able to learn its patterns). Therefore, I prefer to not use any validation set and compute the accuracies on the training set of 100 images directly. Normally, this should never be done, as it becomes impossible to spot where the model starts to overfit, but I believe it is the best compromise I can do, especially given the fact that the goal is more to show how it can be done than actually achieving high accuracies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b38ae0",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a897b7f",
   "metadata": {},
   "source": [
    "## MODELING\n",
    "\n",
    "\n",
    "The idea for training is to have node 0 in charge of loading the metadata and linking the image name with its label. Once this information stored in a table, the table is divided in as many parts as there are nodes performing the training. Hence, this code will adapt based on the number of nodes the user assigns to the training. \n",
    "\n",
    "Node zero will then scatter the information regarding the image names and labels to the different nodes. Each node will then receive its own image names and labels. From there, each node will open, load and transform the images. Hence, the image names are transformed on the same nodes where the model will be trained. I believe it is the best option since (i) each node only needs to load the data it will use to train the model, and therefore (ii) the loading is done in parallel on the different nodes, instead of forcing the nodes to wait for one or several nodes to do the processing and send them the processed images. Also, this allows to (iii) limit the communication costs as there is only a very small amount of data sent from node 0 to the nodes (i.e. image names and labels), in contrast to sending processed images (i.e. tensors). Since the data is loaded on the node that will use it to train the model, it does not need to be moved anymore.\n",
    "\n",
    "Once the nodes have transformed their image names into tensors, a model is trained on each of these nodes. The structure of the model is the same on all nodes: a ResNet 34. However, because it is trained on different subdatasets, the weights will be different. Therefore, in order to keep a consistent model across the subdatasets, I have decided to average the weights of the different models at each epoch. More specifically, after each epoch the nodes will send the weights of their model to node 0, which will gather them, then compute the average, and broadcast these weights again to the nodes. The more epochs, the more communication is being done hence the lower the speed, but in return there is more consistency across the models.\n",
    "\n",
    "After finishing the training, the model is updated and can be saved if required. I addition, I have computed loss and accuracy for each epoch. While it is not a good practice to compute accuracies on the training data instead of a validation set, I have already provided the reasons why I still used that technique (i.e. simplicity and training set already limited to 100 images).\n",
    "\n",
    "\n",
    "In summary, I have exploited data parallelism to distirbute the data and parallelize the training of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cb4b8",
   "metadata": {},
   "source": [
    "I have made the illustration below to highlight key characteristics of the developed model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30aa0a",
   "metadata": {},
   "source": [
    "<img src=\"./data training.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2feb2",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c589594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "# import json # only required at node 0\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "172ce1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0\n",
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7333821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPI\n",
    "from mpi4py import MPI \n",
    "import random \n",
    "\n",
    "comm = MPI.COMM_WORLD    # setup MPI\n",
    "rank = comm.Get_rank()   # process id, Get_rank() returns the process id. Knowing the rank is usually \n",
    "                         # very important to tell which process should do what\n",
    "size = comm.Get_size()  # how many processes are they"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2b3ed",
   "metadata": {},
   "source": [
    "## DATA LOADING\n",
    "\n",
    "Here, the different functions to develop the data loading stage are explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313156b",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "First, the goal is to extract the metadata that is needed and put it in a dataframe. The idea is to open the metadata, extract the image filename, image id and its associated label, and put this information into a new table that will be used to actually access the images. Hence, the goal is not to open the images yet, just to record where they are located. \n",
    "\n",
    "I believe this whole step can be done by a single node as it is not too expensive, at least not on my subset of the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e389b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@profile\n",
    "def load_metadata(DIR, dataset_root, load_type = \"train\", nb_images = 100):\n",
    "    #inspired by the code at Kaggle : XXX\n",
    "\n",
    "    if load_type == \"train\":\n",
    "        \n",
    "        ###### OPENING THE METADATA ######\n",
    "        with open(DIR + 'metadata.json', \"r\", encoding=\"ISO-8859-1\") as file: # \"utf8\"\n",
    "            train = json.load(file)                                                 #type dict, train.keys()\n",
    "        #print(\"Train dict: \", train.keys())\n",
    "        \n",
    "        # Up to here, we have obtained 'train' and 'test', which are dictionaries that contain metadata (NOT the actual images)\n",
    "        # We now need to also extract the actual images\n",
    "        \n",
    "        ###### ORGANIZING METADATA - PUTTING THE METADATA IN A DATAFRAME ######\n",
    "        train_img = pd.DataFrame(train['images'])     # extract the images filenames\n",
    "                                                      # Also contains an id column --> it's the image_id in annotations\n",
    "        train_ann = pd.DataFrame(train['annotations']).drop(columns='image_id') # extract the annotations\n",
    "        train_df = train_img.merge(train_ann, on='id') #id and image_id are the same so we use it to merge both dataframes. \n",
    "        # Dataframe is a table\n",
    "\n",
    "        # print(f\"train_df has length: \",len(train_df))\n",
    "        # print(train_df.head())\n",
    "        # We now have a dataframe for the training data\n",
    "        \n",
    "        # TO BE REMOVED IF USING THE FULL DATASET\n",
    "        # I was able to only download 100 images, therefore I put the nb_images to 100 by default but this can be changed\n",
    "        # if wanting to use the whole dataset\n",
    "        tr_df = train_df[:nb_images]  #Can use only the 100 first values to train to see everything works fine\n",
    "\n",
    "\n",
    "        # NUMBER OF CLASSES WE HAVE IN THE TRAINING DATA\n",
    "        NUM_CL = 64500\n",
    "        # NUM_CL = len(train_df['category_id'].value_counts())  # number of distinct labels = number of outputs of the network\n",
    "        # print(NUM_CL)\n",
    "        # Normally, this should be 64 500 if we use the whole 150GB dataset. \n",
    "        # I use a subset of it so the metadata of my subset is not correct for this number, therefore I set the NUM_CL manually. \n",
    "        # This prevents (range) errors in the output layer of the resnet implementation in PyTorch\n",
    "\n",
    "        \n",
    "        X_Train, Y_Train = tr_df['file_name'].values, tr_df['category_id'].values\n",
    "        # X_Train are the filenames of the images\n",
    "        # Y_Train correspond to the class (category_id) they belong to\n",
    "        \n",
    "        return X_Train, Y_Train\n",
    "\n",
    "#################\n",
    "\n",
    "    elif load_type == \"test\":\n",
    "        #### Need to try it out on a test set of images to be sure it works\n",
    "        # TEST DATA (FOR PREDICTING)\n",
    "        with open(DIR + 'metadata.json', \"r\", encoding=\"ISO-8859-1\") as file: # \"utf8\"\n",
    "            test = json.load(file)    #type dict, train.keys()\n",
    "        #print(\"Test dict: \", test.keys())\n",
    "\n",
    "        ###### ORGANIZING METADATA - PUTTING THE METADATA IN A DATAFRAME ######\n",
    "        test_img = pd.DataFrame(test['images'])     # extract the images filenames\n",
    "                                                      # Also contains an id column --> it's the image_id in annotations\n",
    "        \n",
    "        # PROBABLY NOT CORRECT, BUT I DON'T HAVE ACCESS TO A TEST SET TO TRY IT\n",
    "        # I assume there are no annotations as it is a test set, therefore there should be only the images...\n",
    "        #test_ann = pd.DataFrame(test['annotations']).drop(columns='image_id') # extract the annotations\n",
    "        #test_df = test_img.merge(test_ann, on='id') #id and image_id are the same so we use it to merge both dataframes. \n",
    "        # Dataframe is a table\n",
    "        test_df = test_img\n",
    "        \n",
    "        # If wanting to keep only a subset, by default nb_images = 100\n",
    "        tst_df = test_df[:nb_images]\n",
    "        \n",
    "        X_Test = tst_df['file_name'].values\n",
    "        \n",
    "        return X_Test\n",
    "\n",
    "#################\n",
    "    else:\n",
    "        print(\"Please enter 'train' or 'test' as load_type\")\n",
    "        exit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9933e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "CPU times: user 331 ms, sys: 42.8 ms, total: 374 ms\n",
      "Wall time: 373 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "###### ACCESSING THE DIRECTORY\n",
    "data_root = '/Users/guillaumedelande/Documents/Mes_cours/Master Spéc. Data Science, Big Data - ULB/Mes Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Herbarium_300images'\n",
    "TRAIN_DIR = data_root+ '/train/'\n",
    "TEST_DIR = data_root+'/test/'             # for new predictions\n",
    "\n",
    "rank = 0 # just for debugging\n",
    "\n",
    "if rank == 0:\n",
    "    # ROOT: Only node 0 will load the dataset, therefore the import of json is only required for 0\n",
    "    import json                # Module to read JSON files\n",
    "\n",
    "    #can use the @profile and launch the kernprofiler instead\n",
    "\n",
    "################################################################################\n",
    "################### LOAD METADATA IN NODE 0 ####################################\n",
    "################################################################################\n",
    "    \n",
    "    X_Train, Y_Train = load_metadata(DIR = TRAIN_DIR, dataset_root = data_root, load_type = \"train\", nb_images = 100)\n",
    "    #print(len(X_Train))\n",
    "    #print(len(Y_Train))\n",
    "    \n",
    "    # X_Test = load_metadata(DIR = TEST_DIR, dataset_root = data_root, load_type = \"test\", nb_images = 100)\n",
    "    # print(X_Test)\n",
    "\n",
    "################################################################################\n",
    "######### SCATTER METADATA TO DIFFERENT NODES FOR LOAD AND TRANSFORM ###########\n",
    "################################################################################\n",
    "\n",
    "    # NODE 0's JOB IS NOT FINISHED HERE, SEE 'TRANSFORMATIONS' FOR WHAT NODE 0 ALSO NEEDS TO DO: \n",
    "    # SCATTERING THE LIST OF FILES TO X DIFFERENT NODES THAT WILL LOAD AND TRANSFORM THE IMAGES\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c436eb",
   "metadata": {},
   "source": [
    "## TRANSFORMATIONS\n",
    "\n",
    "\n",
    "We now have the images' filepath as X_Train and their label (Y) as Y_Train.\n",
    "It is now required to load these images from their filepath, and do some transofrmations on them.\n",
    "One file will be in charge of loading them, will then send the loaded image to another node, and that other node will apply some transformations on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7077e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO PLAY WITH FOR OPTIMIZATION\n",
    "\n",
    "IM_SIZE = 64  # Image size. Smaller image size will allow for less data, so faster computing, but won't be optimal at all.\n",
    "              # 32 pixels is probably too small.\n",
    "\n",
    "BATCH = 16    # amount of inputs that will be fed into the neural network at the time\n",
    "              # Usually, we don't train the neural net with each input one at the time, \n",
    "              # we will rather update the weights at each batch input instead of at each single input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd0a5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 264 µs, sys: 672 µs, total: 936 µs\n",
      "Wall time: 944 µs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time \n",
    "\n",
    "# FUNCTIONS \n",
    "\n",
    "###### DEFINING HOW THE IMAGES SHOULD BE TRANSFORMED\n",
    "\n",
    "# Note: the order is important, the .ToTensor() must be at the end\n",
    "Transform = transforms.Compose(\n",
    "    [transforms.Resize((IM_SIZE, IM_SIZE)), #to be played with\n",
    "     transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    #Normalizing the data, we can tune these parameters\n",
    "\n",
    "\n",
    "###### FUNCTION TO RETRIEVE EACH IMAGE AND TRANSOFRM IT\n",
    "\n",
    "# Create a class that will apply the transformations on each image, and has a generator (use 'next' to pass to the next image)\n",
    "# code from the course's TP 1 and from https://www.kaggle.com/ateplyuk/herb2021-pytorch-starter\n",
    "\n",
    "@profile\n",
    "class GetData(Dataset):\n",
    "    \n",
    "    def __init__(self, Dir, FNames, Labels, Transform):\n",
    "        self.dir = Dir               # directory path, dataset_root+ '/train/' or dataset_root+ '/test/\n",
    "        self.fnames = FNames         # filenames\n",
    "        self.transform = Transform   # image transformation parameters\n",
    "        self.labels = Labels         # image labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def __getitem__(self, index):       \n",
    "        \n",
    "        # open the image located at: directoryname+filepath\n",
    "        x = Image.open(os.path.join(self.dir, self.fnames[index])) #open in the directory, the filenames that are stored in fnames\n",
    "    \n",
    "        if \"train\" in self.dir:             \n",
    "            return self.transform(x), self.labels[index]      # if in the train part, return the the transformed image with its (correct) label\n",
    "        \n",
    "        elif \"test\" in self.dir:            \n",
    "            return self.transform(x), self.fnames[index]      # if in test part, return the transformed image with its image path ???\n",
    "        \n",
    "        # return will compute all transformations and load them in memory while yield will do it when asked   \n",
    "        # https://coderscat.com/python-generator-and-yield/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49bf88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "Rank: 0\n",
      "We have 1 workers to open and process the files. There are 100 elements per worker\n",
      "################\n",
      "Rank: 0\n",
      "################\n",
      "I am worker 0, and I have received 100 files to process.\n",
      "I am Node 0, the first element of X_Train is images/604/92/1814367.jpg and the first element of y_Train is 60492\n",
      "I am Node 0 and I got 100 images to process.\n",
      "I am Node 0 and I have opened all my images\n"
     ]
    }
   ],
   "source": [
    "X_workers = size # Can be changed by the user, but by default we will use all the nodes avalailable \n",
    "\n",
    "if rank == 0:\n",
    "    print(\"###############\")\n",
    "    print(f\"Rank: {rank}\")\n",
    "\n",
    "################## CREATE EQUAL-SIZED PARTITIONS OF THE LIST OF IMAGES' FILENAMES\n",
    "    # Code adapted from TP2\n",
    "    \n",
    "    # split the X_Train and Y_Train into equal-sized arrays, each worker will be assigned a series of images to load and to transform\n",
    "    elements_per_worker = len(X_Train) // X_workers      # Divides the number of images by the number of workers assigned to the task\n",
    "    print(f\"We have {X_workers} workers to open and process the files. There are {elements_per_worker} elements per worker\")\n",
    "    filenames_to_scatter = []\n",
    "    \n",
    "    #print(\"X_Train: \",X_Train)\n",
    "\n",
    "    for i in range(X_workers):        # i is the worker's id, --> 'for worker i'\n",
    "        fr = i * elements_per_worker  # fr and to: define a range of filenames to give to the i-th worker\n",
    "        to = fr + elements_per_worker\n",
    "        \n",
    "        if i == X_workers - 1:\n",
    "            # The last worker may have more images to process if <size> does not divide len(all_filenames)\n",
    "            to = len(X_Train)\n",
    "        filenames_to_scatter.append( (X_Train[fr:to],Y_Train[fr:to]) )\n",
    "        # use X_Train = filenames_to_scatter[0][0]\n",
    "        # use Y_Train = filenames_to_scatter[0][1]\n",
    "\n",
    "    #### Up to here, we have a list (filenames_to_scatter) that contains all the partitions (in the form of a list) of filenames to work on.\n",
    "    #### --> We have a list (partitions) of lists (filenames)\n",
    "    #### We now need to scatter each partition to one of the workers\n",
    "    \n",
    "################## SCATTER LIST OF IMAGES' FILENAMES\n",
    "    #scatter would send the data to all workers while we only want the X workers to do that. Therefore, we use send and recv instead\n",
    "\n",
    "    \n",
    "    for i in range(1,X_workers): #to each of the X workers, node 0 excluded #range(1,X_workers+1) if we don't want node 0\n",
    "        comm.send(filenames_to_scatter[i], dest=i, tag=i)\n",
    "        print(f'Process {rank} sent part number {i} of the list of images to node {i}')\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "################## X_workers receive LIST OF IMAGES' FILENAMES\n",
    "\n",
    "#elif rank in range(1, X_workers): #add indent if not using node 0\n",
    "print(\"################\")\n",
    "print(f\"Rank: {rank}\")\n",
    "\n",
    "if rank == 0:\n",
    "    my_filenames = filenames_to_scatter[0] #node 0 already has the data, it just needs to select the part that is assigned to it\n",
    "    \n",
    "if rank != 0:\n",
    "    my_filenames = comm.recv(source=0)\n",
    "    #my_filenames = comm.scatter(filenames_to_scatter, root=0)\n",
    "\n",
    "\n",
    "print(f\"I am worker {rank}, and I have received {len(my_filenames[0])} files to process.\")    \n",
    "\n",
    "my_X_Train = my_filenames[0]\n",
    "my_Y_Train = my_filenames[1] \n",
    "print(f\"I am Node {rank}, the first element of X_Train is {my_X_Train[0]} and the first element of y_Train is {my_Y_Train[0]}\")\n",
    "print('I am Node', rank, 'and I got', len(my_X_Train), 'images to process.')\n",
    "    \n",
    "################################################################################\n",
    "################# X WORKERS TO LOAD AND TRANSFORM IMAGES  ######################\n",
    "################################################################################\n",
    "    \n",
    "# After receiving the list of images to process, they need to process them\n",
    "    \n",
    "################## X_workers open the image files, transform them, and return \n",
    "\n",
    "# Apply transformations on the training set and test set\n",
    "my_trainset = GetData(Dir = TRAIN_DIR, FNames = my_X_Train, Labels = my_Y_Train, Transform  = Transform)\n",
    "\n",
    "# Transform into batches (for PyTorch)\n",
    "trainloader = DataLoader(my_trainset, batch_size=BATCH, shuffle=True) # It is good practice to shuffle the images \n",
    "    \n",
    "print('I am Node', rank, 'and I have opened all my images')\n",
    "sys.stdout.flush()\n",
    "\n",
    "    #print(my_trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dc8dd",
   "metadata": {},
   "source": [
    "## MODEL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "337e5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01     # Learning rate, that will be used by the optimizer. The higher this number, the larger the 'steps'\n",
    "              # of the update of weights (gradient). Larger values will get quicker to a solution, \n",
    "              # but won't yield the most optimal loss. Larger LR also risk to have the gradient to completely get out of the descent!\n",
    "              # Lower LR will go slower, but should go to an optimal solution.\n",
    "\n",
    "EPOCHS = 5    # Number of iterations the model will go through. In other words, the number of times the \n",
    "              # model will go through the whole dataset.\n",
    "\n",
    "NUM_CL = 64500 #not the same as before, but in total the 150 GB dataset has 64 500 different categories (to predict)\n",
    "\n",
    "### NEURAL NETWORK MODEL: feedforward ResNet 34\n",
    "resnet_model = torchvision.models.resnet34(num_classes = NUM_CL)         #num_classes = NUM_CL)\n",
    "\n",
    "### LOSS CRITERION: Cross-entropy loss\n",
    "#Loss function: Cross-entropy loss, good for classification tasks, instead of mse for regression tasks\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "### OPTIMIZER\n",
    "# Adam, will give/adapt the weights of the network during training\n",
    "adam_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=LR) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a1923",
   "metadata": {},
   "source": [
    "Some parameters that can be tuned in this part:  \n",
    "\n",
    "- ```LR```: learning rate \n",
    "- Model type: ResNet 34 but other models exist\n",
    "- Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4fcfe2",
   "metadata": {},
   "source": [
    "## TRAINING function: setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, loader, loss_criterion , optimizer, display_text = False):\n",
    "    \n",
    "    if display_text == True:\n",
    "        print(\"Putting model in training mode\")\n",
    "    model.train() #put the model in training mode, the gradient will adapt\n",
    "    \n",
    "    running_loss = 0.0        #running loss\n",
    "    running_accuracy = 0.0\n",
    "    correct_preds = 0\n",
    "    total = 0\n",
    "\n",
    "    for minibatch, (x_images, y_labels) in enumerate(loader):     \n",
    "        \n",
    "        # TRAINING THE MODEL\n",
    "        \n",
    "        #### FEEDFORWARD\n",
    "        y_output = model(x_images)              # feedforward of the model  \n",
    "        \n",
    "        #### LOSS CRITERION\n",
    "        loss = loss_criterion(y_output, y_labels)    # Compute Y, want it to decrease\n",
    "        # Labels is an int, the index in pred of the float that must get close to 1\n",
    "        \n",
    "        # UPDATE parameters\n",
    "        optimizer.zero_grad()    # reset grads\n",
    "        loss.backward()          # compute new grads\n",
    "        optimizer.step()         # update network weights with new grads\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        # PREDICTION AND PERFORMANCE REVIEW\n",
    "        \n",
    "        # PREDICTION \n",
    "        # we have the output of the network (values), but we need to give the class prediction that is assigned to it\n",
    "        predicted_class = torch.max(y_output.data, 1)[1]  # select the class that has the largest value\n",
    "        #print(\"predicted \",predicted_class)\n",
    "\n",
    "        #### PERFORMANCE\n",
    "        running_loss += loss.detach().item()                   # running loss\n",
    "        \n",
    "        total += y_labels.size(0)      # counts the total number of predictions to perform\n",
    "        correct_preds += (predicted_class == y_labels).sum().item()  # nb correct predictions of classes: where prediction == true class\n",
    "        #print(\"Total number of correct predictions: \",correct_preds)\n",
    "        \n",
    "        running_accuracy = 100 * (correct_preds / total)       # running accuracy, in %\n",
    "        \n",
    "        if display_text == True:        \n",
    "            print('Minibatch: %d | Running Loss: %.4f | Running Accuracy (in pct): %.2f'%( minibatch , running_loss, running_accuracy))\n",
    "    \n",
    "    if display_text == True:\n",
    "        print(\"######################\\nTraining of these minibatches finished\")\n",
    "        print(\"Putting model in evaluation mode\")\n",
    "    \n",
    "    model.eval() # put model in evaluation mode before returning it somewhere. Not sure it is \n",
    "                 # mandatory but it can be seen as a safety measure, so that the weights are not adapted\n",
    "    \n",
    "    return [model, total, correct_preds, running_loss]    #, model.state_dict() # vector of weights, use model.state_dict() to extract the weights and apply operations on them\n",
    "    # think of returning running loss and running accuracy, total, and number of correct predictions, \n",
    "    #to compute a running accuracy for each epoch instead of only minibatch\n",
    "    # so it can be graphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a99cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumes node 0 has split the data parts and sent them to the different nodes\n",
    "\n",
    "if rank in range(X_workers):   #either node 0 or one of the other workers #basically everyone...\n",
    "    \n",
    "    print(\"###########\")\n",
    "    print(f\"Rank: {rank}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #trainloader has been loaded in the part before, so it should still be there on the node\n",
    "    \n",
    "    total_preds = 0\n",
    "    correct_preds = 0\n",
    "    training_history = [] #list of results gathered at each epoch #Will store at each epoch tuples\n",
    "                       # (total_preds, correct_preds, loss)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        ######## ALL NODES TRAIN            \n",
    "        print(\"########\")\n",
    "        print(f\"Rank: {rank} is training.\")\n",
    "        print(\"Epoch: \",epoch)\n",
    "        #################### TRAINING\n",
    "        trained_model = training(loader = trainloader, model = resnet_model, loss_criterion = criterion, optimizer = adam_optimizer, display_text=True)\n",
    "        #training() returns the whole trained model\n",
    "\n",
    "        #################### EXTRACT THE WEIGHTS\n",
    "        trained_weights = trained_model[0].state_dict() # original weights\n",
    "\n",
    "        #################### OTHER INFO ABOUT TRAINING\n",
    "        epoch_total_preds = trained_model[1]\n",
    "        epoch_correct_preds = trained_model[2]\n",
    "        epoch_loss = trained_model[3]\n",
    "        \n",
    "        total_preds += epoch_total_preds\n",
    "        correct_preds += epoch_correct_preds\n",
    "        \n",
    "        training_history.append((epoch_total_preds, epoch_correct_preds, epoch_loss))\n",
    "\n",
    "        #################### AVERAGE THE WEIGHTS: avg each weight of the models\n",
    "        # source: https://discuss.pytorch.org/t/average-each-weight-of-two-models/77008\n",
    "\n",
    "            \n",
    "        ########## GATHER the weights at node 0: ALTERNATIVE IS TO USE ALLGATHER, but it puts extra load on other nodes unnecessarily\n",
    "        gathered_weights = comm.gather(trained_weights, root=0) #what will be received from the nodes: an array of models' weights\n",
    "\n",
    "        if rank == 0: # Let node 0 compute the average\n",
    "            \n",
    "            print(\"########\")\n",
    "            print(f\"Rank: {rank} is gathering the weights.\")      \n",
    "\n",
    "            # Should there be a MPI Barrier ???\n",
    "\n",
    "            ########## SUM all weights\n",
    "            summed_values = dict() #create an empty dict\n",
    "            \n",
    "            with torch.no_grad(): # ensures we don't change the gradients, but only the weights\n",
    "                                  # https://discuss.pytorch.org/t/how-to-change-the-weights-of-a-pytorch-model/41279\n",
    "                                  # https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch\n",
    "                for model_weights in gathered_weights:                # summed_values is an array of each model's weights\n",
    "                    for key in model_weights:                         # each model's weights is a dictionary \n",
    "                                                                      # (with the layer as key, and weights as values of that key)\n",
    "                        if key not in summed_values:\n",
    "                            summed_values[key] = model_weights[key]   # if it is the first model, then there is no key nor values yet, so initialize it\n",
    "\n",
    "                        else:\n",
    "                            summed_values[key] = summed_values[key] + model_weights[key] #add up the model's weights to the existing weights\n",
    "\n",
    "                ########## DIVIDE by number of models\n",
    "                averaged_weights = dict() #empty dict\n",
    "                for key in summed_values:\n",
    "                    averaged_weights[key] = summed_values[key] / len(gathered_weights) # the number of gathered models is denominator of average\n",
    "        \n",
    "        else:\n",
    "            averaged_weights = dict() #we only broadcast the value from node 0 anyways so what's here doesn't matter\n",
    "        \n",
    "        ########## BROADCAST THE NEW WEIGHTS TO THE NODES\n",
    "        new_weights = comm.bcast(averaged_weights, root=0) #each node receives from node 0\n",
    "\n",
    "        ########## UPDATE THE WEIGHTS (FOR NEXT ITERATION) AT EACH NODE\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # source: https://discuss.pytorch.org/t/average-each-weight-of-two-models/77008\n",
    "            # https://discuss.pytorch.org/t/how-to-change-the-weights-of-a-pytorch-model/41279\n",
    "            # https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch\n",
    "            resnet_model.load_state_dict(new_weights) # each node updates its model's weights\n",
    "\n",
    "\n",
    "        print(\"Training this epoch finished\\n#########################\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print(\"################ Training finished ################\")    \n",
    "    print(f\"Total number of predictions: {total_preds}\")\n",
    "    print(f\"Correct predictions: {correct_preds}\")\n",
    "    for epoch_nb, history in enumerate(training_history):\n",
    "        print(f\"Epoch : {epoch_nb+1} | Accuracy of epoch : {100*(history[1]/history[0])} % | Loss: {history[2]}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    ########## SAVING THE MODEL STATE ON DISK FOR FUTURE USE ##########################\n",
    "\n",
    "    \n",
    "    #if rank == 0:\n",
    "    #saving the model on disk for future use\n",
    "        #torch.save(resnet_model.state_dict(), '/Users/guillaumedelande/Documents/Mes_cours/Master Spéc. Data Science, Big Data - ULB/Mes Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project code/resnet_model_dict_state.pth') #better to save the model's parameters, and to load the whole model\n",
    "        # https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference\n",
    "        # the model is defined by: resnet_model = torchvision.models.resnet34(num_classes = 64500) \n",
    "\n",
    "# After all the training is finished, we can go on to the next part: the prediction pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37494bf",
   "metadata": {},
   "source": [
    "# Prediction Pipeline\n",
    "\n",
    "\n",
    "Besides training the model(s), it is of crucial importance to predict classes based on input images. \n",
    "\n",
    "Since this task is somewhat different than the training task, I have decided to use a different pipeline, more adapted to this specific task.\n",
    "\n",
    "Saving the weights of a trained model on disk would take 200MB and I cannot submit such large file. Therefore, I will do the predictions on a new untrained model to avoid having to save the weights of the trained model. This is just to try out the prediction pipeline and to show that it works. If wanting to use the trained model, it is required to save it and to load it. In order to do this, the code to save and to load the model should be uncommented (I have commented it out for now) in the .py files. I have used the kernprofiler to better understand what lines were taking the most time, and based on that I developed the pipeline below to optimize streaming of predictions based on new inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fc6c3",
   "metadata": {},
   "source": [
    "<img src=\"./pipeline.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac6f98",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in the terminal: mpiexec -n 4 python -m mpi4py ex_mpi.py\n",
    "# This will run the code below in 4 processes\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "# import json # only required at node 0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# MPI\n",
    "from mpi4py import MPI \n",
    "import random \n",
    "comm = MPI.COMM_WORLD    # setup MPI\n",
    "rank = comm.Get_rank()   # process id, Get_rank() returns the process id. Knowing the rank is usually \n",
    "                         # very important to tell which process should do what\n",
    "size = comm.Get_size()  # how many processes are they\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d31143",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME AS THE ONE FROM THE TRAINING FILE\n",
    "def load_metadata(DIR, dataset_root, load_type = \"train\", nb_images = 100):\n",
    "    #inspired by the code at Kaggle : XXX\n",
    "\n",
    "    if load_type == \"train\":\n",
    "        \n",
    "        ###### OPENING THE METADATA ######\n",
    "        with open(DIR + 'metadata.json', \"r\", encoding=\"ISO-8859-1\") as file: # \"utf8\"\n",
    "            train = json.load(file)                                                 #type dict, train.keys()\n",
    "        #print(\"Train dict: \", train.keys())\n",
    "        \n",
    "        # Up to here, we have obtained 'train' and 'test', which are dictionaries that contain metadata (NOT the actual images)\n",
    "        # We now need to also extract the actual images\n",
    "        \n",
    "        ###### ORGANIZING METADATA - PUTTING THE METADATA IN A DATAFRAME ######\n",
    "        train_img = pd.DataFrame(train['images'])     # extract the images filenames\n",
    "                                                      # Also contains an id column --> it's the image_id in annotations\n",
    "        train_ann = pd.DataFrame(train['annotations']).drop(columns='image_id') # extract the annotations\n",
    "        train_df = train_img.merge(train_ann, on='id') #id and image_id are the same so we use it to merge both dataframes. \n",
    "        # Dataframe is a table\n",
    "\n",
    "        # print(f\"train_df has length: \",len(train_df))\n",
    "        # print(train_df.head())\n",
    "        # We now have a dataframe for the training data\n",
    "        \n",
    "        # TO BE REMOVED IF USING THE FULL DATASET\n",
    "        # I was able to only download 100 images, therefore I put the nb_images to 100 by default but this can be changed\n",
    "        # if wanting to use the whole dataset\n",
    "        tr_df = train_df[:nb_images]  #Can use only the 100 first values to train to see everything works fine\n",
    "\n",
    "\n",
    "        # NUMBER OF CLASSES WE HAVE IN THE TRAINING DATA\n",
    "        NUM_CL = 64500\n",
    "        # NUM_CL = len(train_df['category_id'].value_counts())  # number of distinct labels = number of outputs of the network\n",
    "        # print(NUM_CL)\n",
    "        # Normally, this should be 64 500 if we use the whole 150GB dataset. \n",
    "        # I use a subset of it so the metadata of my subset is not correct for this number, therefore I set the NUM_CL manually. \n",
    "        # This prevents (range) errors in the output layer of the resnet implementation in PyTorch\n",
    "\n",
    "        \n",
    "        X_Train, Y_Train = tr_df['file_name'].values, tr_df['category_id'].values\n",
    "        # X_Train are the filenames of the images\n",
    "        # Y_Train correspond to the class (category_id) they belong to\n",
    "        \n",
    "        return X_Train, Y_Train\n",
    "\n",
    "#################\n",
    "\n",
    "    elif load_type == \"test\":\n",
    "        #### Need to try it out on a test set of images to be sure it works\n",
    "        # TEST DATA (FOR PREDICTING)\n",
    "        with open(DIR + 'metadata.json', \"r\", encoding=\"ISO-8859-1\") as file: # \"utf8\"\n",
    "            test = json.load(file)    #type dict, train.keys()\n",
    "        #print(\"Test dict: \", test.keys())\n",
    "\n",
    "        ###### ORGANIZING METADATA - PUTTING THE METADATA IN A DATAFRAME ######\n",
    "        test_img = pd.DataFrame(test['images'])     # extract the images filenames\n",
    "                                                      # Also contains an id column --> it's the image_id in annotations\n",
    "        \n",
    "        # I DON'T HAVE ACCESS TO A TEST SET TO TRY IT, BUT SHOULD BE FINE\n",
    "        # I assume there are no annotations as it is a test set, therefore there should be only the images...\n",
    "        #test_ann = pd.DataFrame(test['annotations']).drop(columns='image_id') # extract the annotations\n",
    "        #test_df = test_img.merge(test_ann, on='id') #id and image_id are the same so we use it to merge both dataframes. \n",
    "        # Dataframe is a table\n",
    "        test_df = test_img\n",
    "        \n",
    "        # If wanting to keep only a subset, by default nb_images = 100\n",
    "        tst_df = test_df[:nb_images]\n",
    "        \n",
    "        X_Test = tst_df['file_name'].values\n",
    "        return X_Test\n",
    "\n",
    "#################\n",
    "    else:\n",
    "        print(\"Please enter 'train' or 'test' as load_type\")\n",
    "        exit()\n",
    "      \n",
    "    \n",
    "#################\n",
    "#################\n",
    "\n",
    "def test_transform(DIR, FNames, Transform):               #Labels\n",
    "    \n",
    "    #for image_file in FNames:\n",
    "        \n",
    "    image = Image.open(os.path.join(DIR, FNames)) #open in the directory, the filenames that are stored in fnames\n",
    "                \n",
    "    return (Transform(image), image_file)                # return can also be used, but yield is better when streaming\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa15b9",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if size <= 2:\n",
    "    \n",
    "    print(\"Need at least 4 workers\")\n",
    "    exit()\n",
    "    \n",
    "    \n",
    "###### ACCESSING THE DIRECTORY\n",
    "data_root = '/Users/guillaumedelande/Documents/Mes_cours/Master Spéc. Data Science, Big Data - ULB/Mes Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Herbarium_300images'\n",
    "TRAIN_DIR = data_root+ '/train/'\n",
    "#TEST_DIR = data_root+'/test/'             # I don't have one... so I'll use the train data to try out\n",
    "\n",
    "IM_SIZE = 64\n",
    "\n",
    "\n",
    "Transform = transforms.Compose(\n",
    "    [transforms.Resize((IM_SIZE, IM_SIZE)), #to be played with\n",
    "     transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n",
    "    #Normalizing the data, we can tune these parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb6236",
   "metadata": {},
   "source": [
    "### Node 0 : collecting metadata\n",
    "According to the kernprofiler, the most expensive part on this node is by far the line that loads the json file. Once the list is being done, it is sent to node 1. Since I only have access to a train set, limited to 100 images, I did this step all at once. However, with more images, it is perfectly possible that this step is too expensive. Therefore, I implemented the parameter ```nb_images``` to load only the first 100 images information from the metadata. With some tweaking, this can be used to create batches that are sent to node 1 once the batch is complete. This would prevent the other nodes to be waiting for the whole metadata (JSON) file to be loaded, and to allow them to start working straight away on batches. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:  #Extracting metadata of files, \n",
    "\n",
    "    import json\n",
    "\n",
    "    X_Test = load_metadata(DIR = TRAIN_DIR, dataset_root = data_root, load_type = \"test\", nb_images = 100) #list of image names\n",
    "    \n",
    "    print(len(X_Test))\n",
    "    comm.send(X_Test, dest=1)   # The list of filenames is sent to node 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ee3b3",
   "metadata": {},
   "source": [
    "### Node 1 : opening + transforming the images\n",
    "\n",
    "This node is responsible to load each image from its file, and then to transform it. \n",
    "Process:  \n",
    "- receive metadata (i.e. image names) from node 0.   \n",
    "- for each file in the metadata:  \n",
    "    - opens it  \n",
    "    - transforms it (resizing and tensorizing)  \n",
    "    - sends the tensor image and its name to either node 2 or node 3 (decision rule based on modulo: even numbers to one, uneven to the other)\n",
    "    - sends None once it is finished, to let the next nodes know it is finished\n",
    "    \n",
    "\n",
    "Since the prediction part is another file than the training part, it is important to double check that the transforms are the same as the ones done on the training data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ec56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elif rank == 1:\n",
    "    \n",
    "    X_Test = comm.recv(source=0)   # receive the list of images\n",
    "    print(f\"Rank {rank} rank is starting. Number of images to predict: {len(X_Test)}\")\n",
    "    #print(X_Test[0])\n",
    "    #print(X_Test[1])\n",
    "    \n",
    "    for idx, img in enumerate(X_Test):\n",
    "        \n",
    "        image = Image.open(os.path.join(TRAIN_DIR, img)) #open in the directory, the filenames that are stored in fnames \n",
    "        image = Transform(image)\n",
    "        img_name = img            # return can also be used, but yield is better when streaming\n",
    "        \n",
    "        if idx % 2 == 0:\n",
    "            comm.send((image,img_name), dest = 2) #evenly split\n",
    "            #print(f\"Image {img_name} is being transformed and sent to node 2\")\n",
    "\n",
    "        else:\n",
    "            comm.send((image,img_name), dest = 3)\n",
    "            #print(f\"Image {img_name} is being transformed and sent to node 3\")\n",
    "\n",
    "\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    comm.send((None,None), dest=2) #once finished sending images\n",
    "    comm.send((None,None), dest=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7c0c6",
   "metadata": {},
   "source": [
    "### Nodes 2 and 3: Predicting the class of the image\n",
    "\n",
    "Given a model, the goal is to predict the class. This step is the most expensive as the tensorized images need to pass through the feedforward of the model. Therefore, I assigned two nodes to this step (could have assigned more but it doesn't make much sense because I have only one processor with two cores on my computer...).\n",
    "Each node:  \n",
    "- receives the tensorized image with its name from node 1  \n",
    "- loads the model (here, an untrained model but a trained model could be loaded if it is saved somewhere)\n",
    "- the tensorized image goes through the network to have an output\n",
    "- the output is then converted into a class prediction\n",
    "- result is sent to node 0\n",
    "- None is sent to indicate it has predicted all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54833f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "elif (rank == 2) | (rank == 3): \n",
    "    \n",
    "    \n",
    "    # MODEL USED TO PREDICT\n",
    "    resnet_model = torchvision.models.resnet34(num_classes = 64500) #loading the model structure (this has untrained weights)\n",
    "    \n",
    "    # loading the saved paremeters of the model (after training)\n",
    "    #resnet_model.load_state_dict(torch.load('/Users/guillaumedelande/Documents/Mes_cours/Master Spéc. Data Science, Big Data - ULB/Mes Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project code/resnet_model_dict_state.pth'))\n",
    "    # I DON T DO IT BECAUSE IT TAKES TOO MUCH SPACE ON THE DISK TO SAVE THE STATE_DICT OF THE MODEL AND SEND IT\n",
    "\n",
    "    if rank != 0:\n",
    "        \n",
    "        print(f\"Rank: {rank} is starting predicting\")\n",
    "\n",
    "        while True:\n",
    "    \n",
    "            # Nodes 2 and 3 receive\n",
    "            tensor_image, img_name = comm.recv(source=1) #the images are scattered over the different nodes assigned to predict the outcome\n",
    "            \n",
    "            if tensor_image is None:               # will happen only when it receives from node 0 a (None, None)\n",
    "                print(f\"####### Rank: {rank}, Finished  Predicting #######\")\n",
    "                break\n",
    "            \n",
    "            #print(f\"Rank: {rank} received {img_name}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            resnet_model.eval() #evaluation mode\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                #The unsqueeze() method adds a dimensions at the specified index. The result would have shape:\n",
    "                # https://stackoverflow.com/questions/57237381/runtimeerror-expected-4-dimensional-input-for-4-dimensional-weight-32-3-3-but\n",
    "                tensor_image =  tensor_image.unsqueeze(0)  # Make sure input is what is expected: 4-dimensional weight [64, 3, 7, 7]\n",
    "                # .unsqueeze(0) # --> unsqueeze to add artificial first dimension\n",
    "                #print(tensor_image.shape)\n",
    "                y_output = resnet_model(tensor_image)\n",
    "                predicted_class = torch.max(y_output.data, 1)[1]\n",
    "                predicted_class = predicted_class.item() #extract the value from the tensor\n",
    "\n",
    "            #prediction = (predicted_class, img_name)\n",
    "            #print(f\"Rank: {rank} predicts {img_name} to be {predicted_class}\")\n",
    "            sys.stdout.flush()\n",
    "            comm.send((predicted_class,img_name),dest=0)\n",
    "        \n",
    "        comm.send((None,None), dest=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb42e88",
   "metadata": {},
   "source": [
    "### Node 0: collects the predicted classes\n",
    "\n",
    "Node 0 had a quite fast task at the very beginning, although it heavily depends on the size of the dataset. Since it is the first node that will be finished with its task, I decided to use it to gather the predictions made by nodes 2 and 3. Once finished, it prints out all predictions (to show it works) and then tells the program to shut down, as all the tasks have been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedf2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "\n",
    "    predictions_list = [] #list to store the predictions\n",
    "\n",
    "    print(\"Node 0 is gathering the results from node 2\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        predicted_class, img_name = comm.recv(source=2)\n",
    "\n",
    "        if predicted_class is None:\n",
    "            print(\"### Node 2 is finished sending predictions to node 0\")\n",
    "            break\n",
    "\n",
    "        predictions_list.append((predicted_class, img_name))\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        predicted_class, img_name = comm.recv(source=3)\n",
    "\n",
    "        if predicted_class is None:\n",
    "            print(\"### Node 3 is finished sending predictions to node 0\")\n",
    "            break\n",
    "\n",
    "        predictions_list.append((predicted_class, img_name))\n",
    "\n",
    "    print(f\"Number of predictions: {len(predictions_list)}\")\n",
    "    print(f\"List of predictions: \\n{predictions_list}\")\n",
    "    print(\"### Finished ###\")\n",
    "\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c79d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c3b9bdb",
   "metadata": {},
   "source": [
    "These different cells are put together in the predicting.py file that will be run by the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cb950",
   "metadata": {},
   "source": [
    "# Launching the .py files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b9058",
   "metadata": {},
   "source": [
    "I believe it is clearer to make two separate files. Therefore, I have done two separate .py files: one for training the model (```training.py```), and one for predicting ```predicting.py```). \n",
    "\n",
    "I assume that when done with training, the model's weights are saved on disk. And from there if is easy to start the prediction part (second file). For practical reasons (it takes too much memory, 200MB, so I can't send them), I didn't save the model's weights (line to save the model is commented out in the code). But if wanting to save the trained model, it can simply be commented out. Then, it should be loaded at the beginning of the predictions part. Here, I have done the prediction part on an untrained ResNet model, just to show it is working fine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7b44e",
   "metadata": {},
   "source": [
    "### Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5692a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If wanting to save the model, this line is used to save the weights\n",
    "#torch.save(resnet_model.state_dict(), '/Users/guillaumedelande/Documents/Mes_cours/Master Spéc. Data Science, Big Data - ULB/Mes Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project code/resnet_model_dict_state.pt') #better to save the model's parameters, and to load the whole model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "! mpiexec -n 2 python -m mpi4py /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/training.py    # LAUNCH THE FILE WITH MPI\n",
    "\n",
    "#! mpiexec -np 2 kernprof -l -v /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/training.py       # LAUNCH THE LINE PROFILER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1898ffd",
   "metadata": {},
   "source": [
    "At the bottom of the code (in the .py file), some lines should be uncommented if we want to save the model's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2034e",
   "metadata": {},
   "source": [
    "### Predicting part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcaa3f7",
   "metadata": {},
   "source": [
    "As explained earlier, I don't load a trained model simply because I don't save the trained model's parameters, it's too heavy to send them.\n",
    "\n",
    "Still, I provide the lines below that can be used to load the saved parameters (if wanting to use the trained model), assuming they were saved after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f293b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model structure with untrained wieghts\n",
    "#resnet_model = torchvision.models.resnet34(num_classes = 64500)  \n",
    "\n",
    "#loading the trained parameters\n",
    "#resnet_model.load_state_dict(torch.load('/Users/guillaumedelande/Documents/Mes_cours/Master Spéc. Data Science, Big Data - ULB/Mes Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project code/resnet_model_dict_state.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406ef87",
   "metadata": {},
   "source": [
    "Running the following lines in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "151d5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! mpiexec -n 4 python -m mpi4py /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/predicting.py    # LAUNCH THE FILE WITH MPI\n",
    "\n",
    "#! mpiexec -np 4 kernprof -l -v /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/predicting.py       # LAUNCH THE LINE PROFILER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860e7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b415e6e9",
   "metadata": {},
   "source": [
    "# Improving the model \n",
    "\n",
    "In order to show that I have understood how the ResNet works and how a model could be improved, I will try to improve the accuracy of the model.\n",
    "\n",
    "## Some notes\n",
    "\n",
    "First, as explained in the introduction, my laptop has only one processor with 2 cores and has only 4GB of RAM. In addition, I could only download 100 images of the train set through the Kaggle API. Also, with only 100 images it does not seem very relevant to split the training data into train and validation sets (where validation set can only contain classes the model was trained on...). \n",
    "For these reasons, it would take several  days training model in order to improve an accuracy that is biased (not able to spot overfitting...).\n",
    "\n",
    "Therefore, I believe it is more relevant to focus on what could be done (and explaining what I have learned) to improve a model instead of desperately trying to achieve better accuracies. Tweaking the parameters is also not very difficult, it is mostly time consuming due to the training.\n",
    "\n",
    "\n",
    "\n",
    "## Model choices\n",
    "\n",
    "I used the ResNet 34 model we used in the course practical. One way to achieve better accuracies, is to try out different models. However, I prefered to stick to this one and to tweak some of its parameters rather than trying to fit other models.\n",
    "Improving a model is usually done by finding compromises between processing time and precision/accuracy.\n",
    "\n",
    "Some ways to improve a model would include changing some of its parameters, such as:   \n",
    "\n",
    "- **Image size:** the higher the resolution of the transformed (input) images, the lower the loss should be.  \n",
    "\n",
    "Nevertheless, increasing the resolution has a high cost in terms of processing time as we increase the input size of the data. For most Deep Learning models, the recommended image seems to be 224 pixels square images. Of course, it also depends on the resolution of the original images. If the original images have a very low resolution, it doesn't make much sense to increase their size. I found out that it is very intensive for my computer to process this size.  \n",
    "\n",
    "- **Batch size:** the lower the better for the loss. But a compromise is required  \n",
    "\n",
    "Data (i.e. images) is loaded into batches. The weights will then be updated after each batch instead of each individual image. Increasing the batch size would mean that there are less updates to do, and therefore we could over the whole dataset faster than for a smaller batch size. The lower the batch size the more updates are done and the more time it takes. But it is also more \"representative\" of the data.\n",
    "\n",
    "- **Epochs:** the number of epochs is the number of times/'laps' the training will pass over the whole dataset.\n",
    "\n",
    "For very large datasets, its impossible to go over the dataset many times. For much smaller datasets, it will be much easier to increase the number of epochs. Hence, the number of epochs can be quite high for this smaller dataset, much higher than if the training was run over the whole 150 GB dataset.\n",
    "\n",
    "- **Learning rate:** rate at which the weights are updated.\n",
    "\n",
    "Learning rate, that will be used by the optimizer. The higher this number, the larger the 'steps' of the update of weights (gradient). Larger values will get quicker to a solution, but won't yield the most optimal loss. Larger LR also risk to have the gradient to completely get out of the descent! (and never return).\n",
    "\n",
    "- **Loss function:**\n",
    "\n",
    "Cross-entropy loss is usually a good option for classification tasks, and mse for regression tasks. I will use the cross-entropy loss.\n",
    "\n",
    "- **Optimizer: the way the weights are being adapted**\n",
    "\n",
    "I use the Adam optimizer to adapt the weights of the network during training. Other types of gradients can also be used, such as the famous Stoachastic Gradient Descent (SGD).\n",
    "\n",
    "\n",
    "- **Transformations:**  \n",
    "\n",
    "    - **image shape / Resizing:**  \n",
    "    The general rule is to reshape the original images into square images. However, it is not mandatory at all.\n",
    "    - **normalization:**  \n",
    "    It is good practice to normalize the images pixels. The original images have pixels in range [0,255], which should be transformed. Different normalization parameters can be used to that regard. For instance, most of the ResNet models seem to be using transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225) in PyTorch. I will do so as well, but it could be tweaked.\n",
    "\n",
    "- **Number of nodes:**\n",
    "\n",
    "Of course, since the model is trained in such a way that it can be parallelized and the training spread on as many nodes as the user decides to assign to it, the number of nodes will be important for the accuracy and the processing speed. Because the weights are averaged at each epoch, this should negatively affect the accuracy. However, parallelization allows to considerably (if designed well) increase the training speed!\n",
    "\n",
    "As can be seen above, there are many ways to try to improve a model. It would be very time consuming to try all the different options and fully training the model. Often, the goal is to find a compromise between the speed of training (and predicting) and accuracy of the model. I will tweak some parameters based on what I believe could be the best improvements to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6628b6",
   "metadata": {},
   "source": [
    "Unfortunately, in practice I have had many issues with the computer freezing, because the load on the memory was too high. Therefore, I was not able to try to increase the accuracy as I had planned to do. I would have liked to resize images to squared 224 pixels, as often recommended for this model, but this was impossible as the computer crashed after several epochs. Even a size of 112x112x3 could not be used. I am very annoyed to not be able to improve my model because of my poor laptop performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f59162",
   "metadata": {},
   "source": [
    "Below, an example of some training results achieved when trying to train 30 epochs with batch sizes of 5, learning rate of 0.01, and resizing to squares images of size 112 pixels. Unfortunately the laptop crashed at epoch 18 of both nodes, although it was the only program running on it... Even though this prevents me from tweaking the parameters and achieve higher accuracies, it can still be observed that the loss is decreasing over training epochs, which highlights that the code is actually working but the laptop is not able to run it properly.\n",
    "\n",
    "I have included the small dataset of images that I used in the submission, and suggest to run on it on another computer (I personally don't have access to another one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f5c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "###############\n",
      "Rank: 0\n",
      "We have 2 workers to open and process the files. There are 50 elements per worker\n",
      "Process 0 sent part number 1 of the list of images to node 1\n",
      "################\n",
      "Rank: 0\n",
      "I am worker 0, and I have received 50 files to process.\n",
      "I am Node 0, the first element of X_Train is images/604/92/1814367.jpg and the first element of y_Train is 60492\n",
      "I am Node 0 and I got 50 images to process.\n",
      "I am Node 0 and I have opened all my images\n",
      "################\n",
      "Rank: 1\n",
      "I am worker 1, and I have received 50 files to process.\n",
      "I am Node 1, the first element of X_Train is images/146/77/1450596.jpg and the first element of y_Train is 14677\n",
      "I am Node 1 and I got 50 images to process.\n",
      "I am Node 1 and I have opened all my images\n",
      "Starting training on node 1\n",
      "Starting training on node 0\n",
      "###########\n",
      "Rank: 0\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  0\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 11.5534 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 28.8066 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 47.0947 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 62.2072 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 76.6163 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 91.5245 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 106.5147 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 121.0960 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 135.0388 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 150.8065 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "###########\n",
      "Rank: 1\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  0\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 11.2852 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 28.9707 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 48.8257 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 65.9857 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 82.4094 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 99.6562 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 115.5519 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 131.9795 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 147.2189 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 162.3538 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  1\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 8.6825 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 15.3786 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 19.6826 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 25.1927 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 30.5455 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 35.7264 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 41.6227 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 47.2242 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 53.0772 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 59.3893 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  1\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 6.5729 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 13.5146 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 18.8822 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 23.3537 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 29.4663 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 35.3923 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 41.2044 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 46.8005 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 52.4511 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 57.5106 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  2\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.9275 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 10.1056 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 14.3757 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 19.5547 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 23.5323 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 27.9155 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 33.2933 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 37.0182 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 42.0947 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 47.7041 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  2\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.7590 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.7531 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.1309 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 18.3803 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 23.1418 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 27.7757 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 32.7196 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 38.4862 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 43.0003 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 48.6124 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  3\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.8980 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 11.0727 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 15.3890 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 19.2597 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 23.4449 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 28.4605 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 33.7622 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 38.4911 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 42.8110 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 47.5785 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  3\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.1744 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 10.6256 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 15.7038 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 19.4113 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 23.0302 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 27.3511 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 32.3752 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 37.1513 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 41.9459 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 47.0660 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  4\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.4631 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 9.2055 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 13.9837 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 18.1057 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 23.4584 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 28.7394 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 33.6085 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 38.3411 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 43.6160 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 48.6051 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  4\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.1484 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.3796 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 13.8309 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 18.1401 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 23.4726 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 27.7583 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 32.4120 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 36.9989 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 41.6689 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 46.5474 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  5\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.6186 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 9.1023 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 2 | Running Loss: 13.7436 | Running Accuracy (in pct): 13.33\n",
      "Minibatch: 3 | Running Loss: 17.9854 | Running Accuracy (in pct): 15.00\n",
      "Minibatch: 4 | Running Loss: 22.3793 | Running Accuracy (in pct): 12.00\n",
      "Minibatch: 5 | Running Loss: 27.3522 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 6 | Running Loss: 32.2930 | Running Accuracy (in pct): 8.57\n",
      "Minibatch: 7 | Running Loss: 37.0935 | Running Accuracy (in pct): 7.50\n",
      "Minibatch: 8 | Running Loss: 41.2648 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 9 | Running Loss: 46.7171 | Running Accuracy (in pct): 6.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  5\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.1677 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 10.4625 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 14.7554 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 19.2980 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 24.0344 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 28.5718 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 33.3283 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 38.2062 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 43.4252 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 47.9941 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  6\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.6603 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.0053 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.1554 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 16.7046 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 4 | Running Loss: 21.1622 | Running Accuracy (in pct): 8.00\n",
      "Minibatch: 5 | Running Loss: 25.8683 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 6 | Running Loss: 30.6364 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 34.8627 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 40.1948 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 44.6221 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  6\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.0666 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.4986 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.1776 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 17.1567 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 21.9201 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 26.6077 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 31.4837 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 36.4774 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 41.1371 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 45.4912 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  7\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.8447 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 10.0907 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 14.8260 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 19.1138 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 23.1725 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 27.8801 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 31.7159 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 36.4119 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 40.4772 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 45.1493 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  7\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.7223 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 10.3023 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 15.0573 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 19.6713 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 24.8528 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 29.2022 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 34.0852 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 38.1193 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 43.2140 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 48.1447 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  8\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.9427 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.7731 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 14.4878 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 18.4042 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 21.9690 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 26.3951 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 30.5513 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 35.0939 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 40.0011 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 44.4101 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  8\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.4717 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.6101 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 12.8892 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 16.5474 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 20.8707 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 25.9558 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 30.7507 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 34.6124 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 38.6376 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 43.7743 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  9\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.9597 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.4991 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.2431 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 17.5780 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 22.1249 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 26.5715 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 30.0378 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 35.1431 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 39.2784 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 44.4686 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  9\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.3335 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.2648 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.4472 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 17.8843 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 22.5427 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 27.0754 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 31.7790 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 35.9244 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 39.7009 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 43.7556 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  10\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.9210 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.1928 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 12.5397 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 16.4644 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 20.4526 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 24.1772 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 6 | Running Loss: 28.0279 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 32.6668 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 37.0801 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 43.0351 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  10\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.8462 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.2621 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.4140 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 17.5474 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 20.9521 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 25.4142 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 29.2389 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 33.3754 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 38.2193 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 42.4439 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  11\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.5819 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.3425 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.3503 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 18.4246 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 22.5640 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 26.4560 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 31.1193 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 35.3249 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 40.1529 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 45.2641 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  11\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 5.3025 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 9.5275 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 13.7635 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 18.1035 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 21.9328 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 25.9465 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 29.7282 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 33.5600 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 39.1034 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 44.0443 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  12\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.2139 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.0695 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 11.3467 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 14.8406 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 18.4814 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 22.3126 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 26.8174 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 31.8550 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 36.2152 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 40.2063 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  12\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.2400 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.4659 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 12.6081 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 16.9097 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 21.8729 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 26.1892 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 30.6706 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 34.4868 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 39.4935 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 44.1327 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  13\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.0518 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.1742 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 12.1801 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 16.3113 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 4 | Running Loss: 20.6043 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 5 | Running Loss: 24.5614 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 6 | Running Loss: 28.1068 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 7 | Running Loss: 32.5234 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 8 | Running Loss: 36.2561 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 9 | Running Loss: 40.4919 | Running Accuracy (in pct): 0.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  13\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 3.4992 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 8.6700 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 12.2926 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 15.6167 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 19.4137 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 23.8838 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 28.0914 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 32.4781 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 37.0229 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 40.6023 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  14\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.4096 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.0746 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 12.3284 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 16.2488 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 4 | Running Loss: 19.7596 | Running Accuracy (in pct): 8.00\n",
      "Minibatch: 5 | Running Loss: 23.4467 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 6 | Running Loss: 28.0408 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 31.7578 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 35.4578 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 40.3329 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  14\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.5162 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 7.9034 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 2 | Running Loss: 11.5431 | Running Accuracy (in pct): 13.33\n",
      "Minibatch: 3 | Running Loss: 15.4661 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 4 | Running Loss: 19.4744 | Running Accuracy (in pct): 8.00\n",
      "Minibatch: 5 | Running Loss: 23.7852 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 6 | Running Loss: 26.8482 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 30.6769 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 34.6741 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 39.2370 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  15\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 3.9400 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 7.8556 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 2 | Running Loss: 11.2485 | Running Accuracy (in pct): 13.33\n",
      "Minibatch: 3 | Running Loss: 15.2858 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 4 | Running Loss: 19.2168 | Running Accuracy (in pct): 8.00\n",
      "Minibatch: 5 | Running Loss: 23.0814 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 6 | Running Loss: 26.9741 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 31.2346 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 35.3799 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 38.9166 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  15\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.0130 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 8.0654 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 11.8040 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 15.7291 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 4 | Running Loss: 19.9136 | Running Accuracy (in pct): 8.00\n",
      "Minibatch: 5 | Running Loss: 23.9152 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 6 | Running Loss: 28.0182 | Running Accuracy (in pct): 5.71\n",
      "Minibatch: 7 | Running Loss: 31.7522 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 8 | Running Loss: 35.6427 | Running Accuracy (in pct): 4.44\n",
      "Minibatch: 9 | Running Loss: 40.2312 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  16\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 3.9962 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 7.8469 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 12.1391 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 15.1707 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 18.7681 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 23.2422 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 27.0796 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 31.1126 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 35.2008 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 39.1684 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  16\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.1798 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.3842 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 11.7684 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 3 | Running Loss: 15.4008 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 18.9737 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 23.0619 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 26.9984 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 31.1698 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 36.1070 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 40.7475 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  17\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.2051 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 7.8118 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 11.3768 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 15.0189 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 19.1536 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 22.8022 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 27.1585 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 31.2620 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 35.3133 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 39.2320 | Running Accuracy (in pct): 4.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  17\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.2096 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 1 | Running Loss: 8.0551 | Running Accuracy (in pct): 0.00\n",
      "Minibatch: 2 | Running Loss: 11.4680 | Running Accuracy (in pct): 13.33\n",
      "Minibatch: 3 | Running Loss: 14.6459 | Running Accuracy (in pct): 15.00\n",
      "Minibatch: 4 | Running Loss: 18.2903 | Running Accuracy (in pct): 12.00\n",
      "Minibatch: 5 | Running Loss: 21.8010 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 6 | Running Loss: 25.5543 | Running Accuracy (in pct): 8.57\n",
      "Minibatch: 7 | Running Loss: 28.4526 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 8 | Running Loss: 32.5083 | Running Accuracy (in pct): 8.89\n",
      "Minibatch: 9 | Running Loss: 37.1767 | Running Accuracy (in pct): 8.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 0 is training.\n",
      "Epoch:  18\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 4.0020 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 8.1497 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 11.2588 | Running Accuracy (in pct): 26.67\n",
      "Minibatch: 3 | Running Loss: 14.5690 | Running Accuracy (in pct): 25.00\n",
      "Minibatch: 4 | Running Loss: 18.4006 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 5 | Running Loss: 21.7895 | Running Accuracy (in pct): 16.67\n",
      "Minibatch: 6 | Running Loss: 25.3315 | Running Accuracy (in pct): 14.29\n",
      "Minibatch: 7 | Running Loss: 29.2059 | Running Accuracy (in pct): 12.50\n",
      "Minibatch: 8 | Running Loss: 32.7384 | Running Accuracy (in pct): 11.11\n",
      "Minibatch: 9 | Running Loss: 38.0069 | Running Accuracy (in pct): 10.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "########\n",
      "Rank: 0 is gathering the weights.\n",
      "Training this epoch finished\n",
      "#########################\n",
      "########\n",
      "Rank: 1 is training.\n",
      "Epoch:  18\n",
      "Putting model in training mode\n",
      "Minibatch: 0 | Running Loss: 3.8563 | Running Accuracy (in pct): 20.00\n",
      "Minibatch: 1 | Running Loss: 7.4031 | Running Accuracy (in pct): 10.00\n",
      "Minibatch: 2 | Running Loss: 11.1618 | Running Accuracy (in pct): 6.67\n",
      "Minibatch: 3 | Running Loss: 14.6892 | Running Accuracy (in pct): 5.00\n",
      "Minibatch: 4 | Running Loss: 18.0507 | Running Accuracy (in pct): 4.00\n",
      "Minibatch: 5 | Running Loss: 21.5437 | Running Accuracy (in pct): 3.33\n",
      "Minibatch: 6 | Running Loss: 25.0547 | Running Accuracy (in pct): 2.86\n",
      "Minibatch: 7 | Running Loss: 29.0614 | Running Accuracy (in pct): 2.50\n",
      "Minibatch: 8 | Running Loss: 33.2910 | Running Accuracy (in pct): 2.22\n",
      "Minibatch: 9 | Running Loss: 36.8093 | Running Accuracy (in pct): 2.00\n",
      "######################\n",
      "Training of these minibatches finished\n",
      "Putting model in evaluation mode\n",
      "Training this epoch finished\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! mpiexec -n 2 python -m mpi4py /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/training.py    # LAUNCH THE FILE WITH MPI\n",
    "\n",
    "#! mpiexec -np 2 kernprof -l -v /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/training.py       # LAUNCH THE LINE PROFILER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56513db",
   "metadata": {},
   "source": [
    "Therefore, I decided to only train the model on images of size 64, to avoid the computer to completely freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e70cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "###############\n",
      "Rank: 0\n",
      "We have 2 workers to open and process the files. There are 50 elements per worker\n",
      "Process 0 sent part number 1 of the list of images to node 1\n",
      "################\n",
      "Rank: 0\n",
      "I am worker 0, and I have received 50 files to process.\n",
      "I am Node 0, the first element of X_Train is images/604/92/1814367.jpg and the first element of y_Train is 60492\n",
      "I am Node 0 and I got 50 images to process.\n",
      "I am Node 0 and I have opened all my images\n",
      "################\n",
      "Rank: 1\n",
      "I am worker 1, and I have received 50 files to process.\n",
      "I am Node 1, the first element of X_Train is images/146/77/1450596.jpg and the first element of y_Train is 14677\n",
      "I am Node 1 and I got 50 images to process.\n",
      "I am Node 1 and I have opened all my images\n",
      "Starting training on node 0\n",
      "Starting training on node 1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! mpiexec -n 2 python -m mpi4py /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/training.py    # LAUNCH THE FILE WITH MPI\n",
    "\n",
    "#! mpiexec -np 2 kernprof -l -v /Users/guillaumedelande/Documents/Mes_cours/Master\\ Spéc.\\ Data\\ Science,\\ Big\\ Data\\ -\\ ULB/Mes\\ Notes/Semestre2/INFO-H515_BigData_DistributedManagementAndScalableAnalytics/Project/Project\\ code/training.py       # LAUNCH THE LINE PROFILER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b13e1",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c1a0b",
   "metadata": {},
   "source": [
    "In this assignment, I wanted to emphasize more on the understanding of all the different tasks than to actually try achieving high accuracies, especially given my laptop's specs and the extremely small dataset. For that reason, I spent more time on the implementation (Task 1 to 4) than on the Task 5 (tweaking parameters to improve accuracy). Still, I believe I have fulfilled all of the different tasks from the assignment.\n",
    "\n",
    "I have also done my best to comment the code and to provide additional information where needed.\n",
    "\n",
    "Unfortunately, my laptop crashed most of the time when trying to increase some parameters to improve the accuracy. I believe that it increased the load of the RAM too much, until the laptop freezed. I hope this will not affect the grading of my submission too much, as I have spent a fair amount of time in designing the model and the code is working fine until I use too specific parameters.\n",
    "\n",
    "Overall, I have found this assignment to be quite challenging as it required to master many different concepts, such as learning PyTorch and its very specific (and sometimes complex) functions, using MPI in a specific way, thinking about the optimal parallel implementation for each task, understanding how weights can be averaged, and more. Nevertheless, I feel I have learned a lot from it and it is a very good starting point for the future. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a82ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
